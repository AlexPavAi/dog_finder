{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f089fce-605e-42fb-ac96-ef6e26c81125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Install clip\n",
    "! pip install torch torchvision -q\n",
    "! pip install ftfy regex tqdm -q\n",
    "! pip install git+https://github.com/openai/CLIP.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a22e33-1a84-4695-814c-fb9e28bcc272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install w&b for visualization\n",
    "! pip install wandb -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c65c78a-35ad-47cf-be71-a1571fd9bf6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hugging Face's datasets for the stanford dogs ds\n",
    "! pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb5c45c1-92bb-4ebe-b557-8a542d731072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List, Dict\n",
    "import clip\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d99feca4-e381-4fbb-92a7-6ea0095feb27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "DATA_ROOT = \"data/\"\n",
    "VERIVIED_DOG_DATA = os.path.join(DATA_ROOT, \"certain_matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8b65ddc-614f-4507-b450-1a58bde50dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the stanford dogs ds for negative examples\n",
    "STANFORD_DOGS = load_dataset(\"Alanox/stanford-dogs\").shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bbdbbd9-c2c4-405d-860f-3d010d8be36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL_TYPE = 'ViT-L/14@336px'\n",
    "# ml.r5.24xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "293f4aa0-4eae-4aab-a4a2-3b1efdf30c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device= cuda\n"
     ]
    }
   ],
   "source": [
    "# MODEL_TYPE = 'ViT-L/14@336px'\n",
    "MODEL_TYPE = \"ViT-B/32\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(MODEL_TYPE, device)\n",
    "model = model.float()\n",
    "\n",
    "print(\"Using device=\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "116f2aff-17a2-486d-b659-1d70229b0820",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose layers not to train. From `model.named_parameters()`\n",
    "# params_to_freeze = []\n",
    "params_to_freeze = ['positional_embedding',\n",
    " 'text_projection',\n",
    " 'visual.class_embedding',\n",
    " 'visual.positional_embedding',\n",
    " 'visual.proj',\n",
    " 'visual.conv1.weight',\n",
    " 'visual.ln_pre.weight',\n",
    " 'visual.ln_pre.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a23b1e3-686f-443f-864b-2f30d7464a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing positional_embedding\n",
      "Freezing text_projection\n",
      "Freezing visual.class_embedding\n",
      "Freezing visual.positional_embedding\n",
      "Freezing visual.proj\n",
      "Freezing visual.conv1.weight\n",
      "Freezing visual.ln_pre.weight\n",
      "Freezing visual.ln_pre.bias\n"
     ]
    }
   ],
   "source": [
    "temperature = None\n",
    "for name, param in model.named_parameters():\n",
    "    if name in params_to_freeze:\n",
    "        print(f\"Freezing {name}\")\n",
    "        param.requires_grad = False\n",
    "    # if name == \"logit_scale\":\n",
    "    #     temperature = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "644cb79e-8f94-4e4e-a5e1-6b5e5c8ba977",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17eba610-8a21-4b10-8432-f7b039ea8078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, root, negative_ds, transform, num_negatives=5):\n",
    "        self.dataset = ImageFolder(root, transform=transform)\n",
    "        self.num_negatives = num_negatives\n",
    "        self.negative_ds = negative_ds\n",
    "        self.dog_indices = self.get_dog_indices()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Each indexing returns the components that would later create 2 image vectors, of the form: [positive_dog, [negative_dog*num_negatives]]\n",
    "        where `positive_dog` is a dog from our dataset, for which we have a match, and `negative_dog`s are random\n",
    "        dogs from the \"dogs of stanford\" dataset, for which we don't have a match, thus they serve as negative examples only.\n",
    "\n",
    "        \"\"\"\n",
    "        dog_label = list(self.dog_indices.keys())[index % len(self.dog_indices)]\n",
    "        pos_1_idx, pos_2_idx = random.sample(self.dog_indices[dog_label], 2)\n",
    "        positive_image_1, _ = self.dataset[pos_1_idx]\n",
    "        positive_image_2, _ = self.dataset[pos_2_idx]\n",
    "        negative_images_1, negative_images_2 = self.get_negative_images()\n",
    "        assert len(negative_images_1) == len(negative_images_2)\n",
    "        return positive_image_1, positive_image_2, negative_images_1, negative_images_2\n",
    "\n",
    "    def get_dog_indices(self) -> Dict[int, List[int]]:\n",
    "        # Logic to enforce a uniform probability for each dog\n",
    "        dog_indices = {}\n",
    "        for idx, (_, label) in enumerate(self.dataset.imgs):\n",
    "            if label not in dog_indices:\n",
    "                dog_indices[label] = []\n",
    "            dog_indices[label].append(idx)\n",
    "\n",
    "        # Remove folders with only one image\n",
    "        dog_indices = {\n",
    "            label: indices for label, indices in dog_indices.items() if len(indices) > 1\n",
    "        }\n",
    "        return dog_indices\n",
    "\n",
    "    def get_negative_images(self) -> List[torch.Tensor]:\n",
    "        # Sample self.num_negatives examples from dataset for each positive dog\n",
    "        indices = random.sample(\n",
    "            range(self.negative_ds[\"full\"].num_rows), self.num_negatives * 2\n",
    "        )\n",
    "        images = [self.transform(self.negative_ds[\"full\"][idx][\"image\"]) for idx in indices]\n",
    "        return images[:self.num_negatives], images[self.num_negatives:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dog_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e0c068c-920f-475a-b0bb-4b9a2b857375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_NEGATIVES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7a3e8b29-ff09-408b-9da5-d648c2e0acfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dog_dataset = DogDataset(\n",
    "    root=VERIVIED_DOG_DATA, \n",
    "    negative_ds=STANFORD_DOGS, \n",
    "    transform=preprocess, \n",
    "    num_negatives=NUM_NEGATIVES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9550226-cfc6-4cc0-ac7c-b59b2b3d908d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train - test split\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_proportion = 0.8\n",
    "test_proportion = 1 - train_proportion\n",
    "\n",
    "num_samples = len(dog_dataset)\n",
    "num_train_samples = int(train_proportion * num_samples)\n",
    "num_test_samples = num_samples - num_train_samples\n",
    "\n",
    "train_set, test_set = random_split(dog_dataset, [num_train_samples, num_test_samples])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69ed5f5f-7809-4478-8423-602805dbfdae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create new dir for test set & checkpoints\n",
    "\n",
    "NEW_RUN_NAME = f\"RUN_{datetime.now().strftime('%d_%b_%y_%H-%M-%S')}\"\n",
    "NEW_RUN_DIR = os.path.join(\"artifacts\", NEW_RUN_NAME)\n",
    "PATH_TO_CHECKPOINTS = os.path.join(NEW_RUN_DIR, \"checkpoints\")\n",
    "\n",
    "os.mkdir(NEW_RUN_DIR)\n",
    "os.mkdir(PATH_TO_CHECKPOINTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6371a468-98b8-4dfb-83c8-e308536bd9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the test set to later evaluate performance on the test set only\n",
    "\n",
    "with gzip.open(os.path.join(NEW_RUN_DIR, 'test_data.pth.gz'), 'wb') as f:\n",
    "    torch.save(test_set, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8cab3785-5a37-4929-849a-e1396e8fe40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set training params\n",
    "# learning_rate = 5e-6\n",
    "learning_rate = 1e-6\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b33c9-c89b-4ef1-af96-48c98920e6de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init w&b\n",
    "wandb.init(\n",
    "    project=\"dogfinder\",\n",
    "    config={\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_negatives\": dog_dataset.num_negatives,\n",
    "        \"temperature\": temperature,\n",
    "        \"model_type\": MODEL_TYPE,\n",
    "        \"run_name\": NEW_RUN_NAME,\n",
    "        \"frozen_params\": params_to_freeze\n",
    "    },\n",
    "    save_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b515bdc-1b0b-41ec-8675-5703799253f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear cache\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f7dafc3-4561-463c-9932-5fd57dfac632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper funcs\n",
    "def normalize_features(features):\n",
    "    return features / (torch.norm(features, dim=-1, keepdim=True))\n",
    "\n",
    "def normalized_features_to_logits(anchor_features, positive_features, negatives_features, temperature=None):  \n",
    "    positive_similarity = (anchor_features * positive_features).sum(dim=-1)\n",
    "    negative_similarity = torch.stack(\n",
    "        [\n",
    "            (anchor_features * negative_feature).sum(dim=-1)\n",
    "            for negative_feature in negatives_features\n",
    "        ],\n",
    "        dim=-1)\n",
    "    logits = (\n",
    "      torch.cat([positive_similarity.unsqueeze(-1), negative_similarity], dim=-1)\n",
    "    )\n",
    "    \n",
    "    if temperature:\n",
    "        logits /= temperature\n",
    "    return logits\n",
    "\n",
    "\n",
    "\n",
    "def run_through_loop(pos_1, pos_2, negs_1, negs_2):\n",
    "\n",
    "    # Encode the images\n",
    "    pos_1_features = model.encode_image(pos_1.float())\n",
    "    pos_2_features = model.encode_image(pos_2.float())\n",
    "    negs_1_features = [model.encode_image(negative.float()) for negative in negs_1]\n",
    "    negs_2_features = [model.encode_image(negative.float()) for negative in negs_2]\n",
    "\n",
    "    pos_1_features = normalize_features(pos_1_features) \n",
    "    pos_2_features = normalize_features(pos_2_features)\n",
    "    negs_1_features = [\n",
    "        normalize_features(negative_feature) for negative_feature in negs_1_features\n",
    "        ]\n",
    "    negs_2_features = [\n",
    "        normalize_features(negative_feature) for negative_feature in negs_2_features\n",
    "      ]\n",
    "\n",
    "    # Calculate the contrastive loss\n",
    "    # Direction 1: logits per row\n",
    "    row_logits = normalized_features_to_logits(\n",
    "        anchor_features=pos_1_features, \n",
    "        positive_features=pos_2_features, \n",
    "        negatives_features=negs_2_features,\n",
    "        temperature=temperature\n",
    "        )\n",
    "    # Direction 2: logits per col\n",
    "    col_logits = normalized_features_to_logits(\n",
    "        anchor_features=pos_2_features, \n",
    "        positive_features=pos_1_features, \n",
    "        negatives_features=negs_1_features,\n",
    "        temperature=temperature\n",
    "        )\n",
    "    # The positive example is always at the 1st index\n",
    "    labels = torch.zeros(row_logits.shape[0], dtype=torch.long, device=device)\n",
    "    row_loss = torch.nn.functional.cross_entropy(row_logits, labels) \n",
    "    col_loss = torch.nn.functional.cross_entropy(col_logits, labels) \n",
    "    loss = (row_loss + col_loss) / 2.0\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa85387f-0aa6-41df-a70d-c68ed6cb8c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom calculations to run on the validation set\n",
    "\n",
    "def similarity(embedding1, embedding2):\n",
    "    return torch.nn.functional.cosine_similarity(embedding1, embedding2).item()\n",
    "\n",
    "def get_top_n_stats(row_embeddings, col_embeddings):\n",
    "    indices_of_correct_image_in_predictions = []\n",
    "\n",
    "    for ii, row_dog in enumerate(row_embeddings):\n",
    "        similarities = []\n",
    "        for col_dog in col_embeddings:\n",
    "            similarities.append(similarity(row_dog, col_dog))\n",
    "\n",
    "        sorted_similarities = sorted(\n",
    "            enumerate(similarities), key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "        sorted_indices = [i for i, _ in sorted_similarities]\n",
    "        correct_image_index = sorted_indices.index(ii)\n",
    "\n",
    "        indices_of_correct_image_in_predictions.append(correct_image_index)\n",
    "\n",
    "    as_np = np.asarray(indices_of_correct_image_in_predictions)\n",
    "    total_dp = len(indices_of_correct_image_in_predictions)\n",
    "    top_1_count = len(as_np[as_np == 1])\n",
    "    top_5_count = len(as_np[as_np <= 5])\n",
    "    top_10_count = len(as_np[as_np <= 10])\n",
    "\n",
    "    print(f\"Total datapoints: {total_dp}\")\n",
    "    print(f\"# of answer is in top 1: {top_1_count} = {top_1_count/total_dp:.3f}%\")\n",
    "    print(f\"# of answer is in top 5: {top_5_count} = {top_5_count/total_dp:.3f}%\")\n",
    "    print(f\"# of answer is in top 10: {top_10_count} = {top_10_count/total_dp:.3f}%\")\n",
    "\n",
    "    print(\"indices_of_correct_image_in_predictions\", indices_of_correct_image_in_predictions)\n",
    "    return total_dp, top_1_count, top_5_count, top_10_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e9549-381c-4c75-bdf1-c8161d6add19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top n baseline:\n",
    "with torch.no_grad():        \n",
    "    row_embeddings = []\n",
    "    col_embeddings = []\n",
    "    for pos_1, pos_2, negs_1, negs_2 in tqdm(test_loader):\n",
    "        pos_1 = pos_1.to(device)\n",
    "        pos_2 = pos_2.to(device)\n",
    "            \n",
    "\n",
    "        pos1_features = model.encode_image(pos_1.float())\n",
    "        pos2_features = model.encode_image(pos_2.float())\n",
    "        row_embeddings.extend([data_point.unsqueeze(0) for data_point in pos1_features])\n",
    "        col_embeddings.extend([data_point.unsqueeze(0) for data_point in pos2_features])\n",
    "\n",
    "    total_dp, top_1_count, top_5_count, top_10_count = get_top_n_stats(\n",
    "        row_embeddings, col_embeddings\n",
    "    )\n",
    "\n",
    "# Log the metrics to W&B\n",
    "wandb.log({\"total_dp\": total_dp, \n",
    "           \"top_1_count\":top_1_count, \n",
    "           \"top_5_count\":top_5_count, \n",
    "           \"top_10_count\": top_10_count, \n",
    "           \"epoch\": -1}\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27f5e2-fade-414e-a390-6c1839fd03c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for pos_1, pos_2, negs_1, negs_2 in tqdm(train_loader):\n",
    "        pos_1 = pos_1.to(device)\n",
    "        pos_2 = pos_2.to(device)\n",
    "        negs_1 = [neg.to(device) for neg in negs_1]\n",
    "        negs_2 = [neg.to(device) for neg in negs_2]\n",
    "        optimizer.zero_grad()\n",
    "        loss = run_through_loop(pos_1, pos_2, negs_1, negs_2)\n",
    "        \n",
    "        # Update the model parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "    # Compute validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        \n",
    "        row_embeddings = []\n",
    "        col_embeddings = []\n",
    "        for pos_1, pos_2, negs_1, negs_2 in tqdm(test_loader):\n",
    "            pos_1 = pos_1.to(device)\n",
    "            pos_2 = pos_2.to(device)\n",
    "            negs_1 = [neg.to(device) for neg in negs_1]\n",
    "            negs_2 = [neg.to(device) for neg in negs_2]\n",
    "            \n",
    "            val_loss = run_through_loop(pos_1, pos_2, negs_1, negs_2)\n",
    "            validation_loss += val_loss.item()\n",
    "            \n",
    "            pos1_features = model.encode_image(pos_1.float())\n",
    "            pos2_features = model.encode_image(pos_2.float())\n",
    "            row_embeddings.extend([data_point.unsqueeze(0) for data_point in pos1_features])\n",
    "            col_embeddings.extend([data_point.unsqueeze(0) for data_point in pos2_features])\n",
    "\n",
    "        validation_loss /= len(test_loader)\n",
    "        total_dp, top_1_count, top_5_count, top_10_count = get_top_n_stats(\n",
    "            row_embeddings, col_embeddings\n",
    "        )\n",
    "        \n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\"\n",
    "    )\n",
    "    # Log the metrics to W&B\n",
    "    wandb.log({\"train_loss\": train_loss, \"validation_loss\": validation_loss, \"epoch\": epoch + 1})\n",
    "    wandb.log({\"total_dp\": total_dp, \n",
    "               \"top_1_count\":top_1_count, \n",
    "               \"top_5_count\":top_5_count, \n",
    "               \"top_10_count\": top_10_count, \n",
    "               \"epoch\": epoch + 1}\n",
    "             )\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"train_loss\": train_loss,\n",
    "        \"validation_loss\": validation_loss,\n",
    "    }\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(PATH_TO_CHECKPOINTS, f\"checkpoint_epoch_{epoch + 1}.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664ca70-3c59-4a86-87b8-029f52e87fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
